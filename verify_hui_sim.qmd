---
title: "Analysis"
date: "`r Sys.Date()`"
author: "Rich Evans, PhD, PSTAT"
format: pdf
number-sections: true
execute: 
  echo: true
output-file: "analysis_results"
reticulate:
  python: "/Users/richardevans/.virtualenvs/r-reticulate/bin/python"
---

This runs everything

What I do is look at the median for real.data and see if it falls within the hui confidence intervals. If they do, I call it "acceptable." The hui intervals are quite wide for n_real = 500.

small n_real take about 15 minutes. With n_real = 20,000 it takes 5.5 hours.


```{r}

#all the necessary functions
source(here::here("hui_tvae_functions2.R"))
```

hui simulation function changed to use two "real" datasets. This way I can check the hui and walter estimates for accuracy against known values from the generated data.

MUST RUN THIS FIRST BEFORE THE SIMULATION

```{r}
hui.sim <- function(
  p_class1_real = 0.8,
  p_class1_pop2 = 0.2,
  n_real1 = 500,
  n_real2 = 500,
  p1_0 = 0.2, # 1 - sp test 1
  p1_1 = 0.8, #se test 1
  p2_0 = 0.10, # 1 -sp test 2
  p2_1 = 0.8 # se test 2
 
) {
  #####"real" dataset which is pop1
  df <- generate_real_data(
    p_class1_real = p_class1_real,
    n_real = n_real1,
    p1_0 = p1_0, # 1 - sp test 1
    p1_1 = p1_1, #se test 1
    p2_0 = p2_0, # 1 -sp test 2
    p2_1 = p2_1
  )

  ######generate pop2 data
  synth.output <- generate_real_data(
    p_class1_real = p_class1_pop2,
    n_real = n_real2,
    p1_0 = p1_0, # 1 - sp test 1
    p1_1 = p1_1, #se test 1
    p2_0 = p2_0, # 1 -sp test 2
    p2_1 = p2_1
  ) 

#print(table(df$test1, df$test2))
#print("----")
#print(table(synth.output$test1, synth.output$test2))
  ##### hui and walter
  hui <- hui_walter_mle_se(
    table(df$test1, df$test2),
    table(synth.output$test1, synth.output$test2)
  )


  real.data <- c(as.vector(calc_se_sp(df)), mean(df$class), NA)
  names(real.data) <- c("Se1", "Sp1", "Se2", "Sp2", "Prev_pop1", "Prev_pop2")

  synthetic.data <- c(
    as.vector(calc_se_sp(synth.output)),
    NA,
    mean(synth.output$class)
  )
  names(synthetic.data) <- c(
    "Se1",
    "Sp1",
    "Se2",
    "Sp2",
    "Prev_pop1",
    "Prev_pop2"
  )

  hui.estimates <- hui$estimates

  return(rbind(hui.estimates, real.data, synthetic.data))



  sim_summary_table <- function(
  results,
  block_size = 3,
  shade = "#A0A0A0",
  probs = c(0.025, 0.975),
  kable_args = list()
) {
  # deps
  stopifnot(length(probs) == 2)
  if (!requireNamespace("dplyr", quietly = TRUE)) {
    stop("Need {dplyr}.")
  }
  if (!requireNamespace("kableExtra", quietly = TRUE)) {
    stop("Need {kableExtra}.")
  }
  if (!requireNamespace("reshape2", quietly = TRUE)) {
    stop("Need {reshape2}.")
  }
  if (!requireNamespace("knitr", quietly = TRUE)) {
    stop("Need {knitr} (for kable).")
  }

  # reshape
  results_df <- reshape2::melt(results)
  names(results_df) <- c("source", "stat", "iteration", "value")

  # summarize
  suppressPackageStartupMessages({
    library(dplyr)
  })

  results_summary <- results_df %>%
    dplyr::group_by(source, stat) %>%
    dplyr::summarise(
      lower = stats::quantile(value, probs[1], na.rm = TRUE),
      median_val = stats::median(value, na.rm = TRUE),
      upper = stats::quantile(value, probs[2], na.rm = TRUE),
      .groups = "drop"
    ) %>%
    dplyr::arrange(stat)

  # styling indices
  n <- nrow(results_summary)
  grp <- if (n > 0) ((seq_len(n) - 1) %/% block_size) + 1 else integer(0)
  triplet_odd <- which(grp %% 2 == 1)
  dividers <- if (n > 0) seq(block_size, n, by = block_size) else integer(0)
  if (n > 0 && (n %% block_size) != 0) {
    dividers <- c(dividers, n)
  }

  # build kable
  suppressPackageStartupMessages({
    library(kableExtra)
  })
  kb <- do.call(knitr::kable, c(list(x = results_summary), kable_args)) %>%
    kableExtra::row_spec(triplet_odd, background = shade, color = "black") %>%
    kableExtra::row_spec(
      dividers,
      extra_css = "border-bottom: 3px solid #000;"
    ) %>%
    kableExtra::kable_styling(full_width = FALSE)

  # return both
  list(summary = results_summary, table = kb)
}

}
```




this uses cond indep hui and walter

```{r}

library(tictoc)

tic("time_hui_sim")

results <- replicate(200,  
  hui.sim(
  p_class1_real = 0.8,
  p_class1_pop2 = 0.2,
  n_real1 = 500,
  n_real2 = 500,))


#make the results into a nice table
sim_summary_table(results)$table

# the hui estimates modified to look at the effect of larger N and smaller for pop2 on the spread of the point estimates.
#the idea is to see how large of a synthetic data set to make.

sim_summary_table(results)$summary |> filter(source == "hui.estimates") |>
  mutate(spread = upper - lower) |> select(stat, spread)




toc()
```


just a quick little test
```{r}
po1 <- generate_real_data(p_class1_real=0.8)
po2 <- generate_real_data(p_class1_real=0.2)

 foo<- hui_walter_mle_se(
  table(po1$test1, po1$test2),
  table(po2$test1, po2$test2)
)


foo$estimates

```

I had to run this setup once.

```{r}
# --- Fix for joblib/loky resource_tracker warnings on restart ---
# These appear when reticulate's embedded Python shuts down and finds leftover semaphores or temp memmaps.
# This block sets up a stable temp dir, safe parallel backend, and silent teardown.

# Create a stable temp folder for joblib
dir.create("~/tmp/joblib", recursive = TRUE, showWarnings = FALSE)
Sys.setenv(JOBLIB_TEMP_FOLDER = "~/tmp/joblib")

# Optionally upgrade joblib/loky for better cleanup behavior
if (requireNamespace("reticulate", quietly = TRUE)) {
  try(reticulate::py_install(
    c("joblib>=1.4", "loky>=3.5"),
    envname = "r-reticulate", pip = TRUE
  ))
}

# Define a Python-safe parallel example with clean exit
if (requireNamespace("reticulate", quietly = TRUE)) {
  reticulate::py_run_string("
import os
os.makedirs(os.getenv('JOBLIB_TEMP_FOLDER', '/tmp'), exist_ok=True)
from joblib import Parallel, delayed, parallel_backend

def work(i):
    # example workload
    return i*i

# Use threading backend (no semaphores)
with parallel_backend('threading'):
    OUT = Parallel(n_jobs=-1)(delayed(work)(i) for i in range(1000))

# Clean shutdown of workers
import multiprocessing as mp
for p in mp.active_children():
    p.terminate()
")
  out <- reticulate::py$OUT
  print(str(out))
}

# Optional: silence resource_tracker warnings entirely (use sparingly)
Sys.setenv(PYTHONWARNINGS = "ignore:resource_tracker")

# Summary:
# - Prevents leaked semaphore warnings at R shutdown.
# - Keeps joblib temp files in one reusable folder.
# - Uses threads for safety (no process semaphores).
# - Safe to keep in .Rprofile or call before running reticulate simulations.
```

