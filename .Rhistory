print(list(calc_se_sp_ci(df),calc_se_sp_ci(res$synthetic_df)))
#plot(res$training_loss$Epoch, res$training_loss$Loss, type="l", lwd=2)
#res$training_loss$loss
hui <- hui_walter_mle_se(table(df$test1,df$test2), table(res$synthetic_df$test1,res$synthetic_df$test2))
hui <- hui_walter_mle_se(table(df$test1,df$test2), table(res$synthetic_df$test1,res$synthetic_df$test2))
#Check
list(hui$estimates, calc_se_sp_ci(df),calc_se_sp_ci(res$synthetic_df))
hui$ci          # Wald 95% CIs
source(here("hui_synth_tvae_method_binary_diag2.qmd"))
source(here("hui_tvae_function.R"))
source(here::here("hui_tvae_function.R"))
source(here::here("hui_tvae_functions.R"))
source(here::here("hui_tvae_functions.R"))
df <- generate_real_data(class0 = 5000
, class1 = 5000 #count in class =1
,p1_0 = 0.2 # 1 - sp test 1
,p1_1 = 0.8 #se test 1
,p2_0 = 0.10 # 1 -sp test 2
,p2_1 = 0.8) # se test 2
res <- tvae_synthesize_binary(df, n_synth = 5000, p_class1 = 0.8, epochs = 100)
print(list(calc_se_sp_ci(df),calc_se_sp_ci(res$synthetic_df)))
hui <- hui_walter_mle_se(table(df$test1,df$test2), table(res$synthetic_df$test1,res$synthetic_df$test2))
#Check
list(hui$estimates, calc_se_sp_ci(df),calc_se_sp_ci(res$synthetic_df))
source(here::here("hui_tvae_functions.R"))
df <- generate_real_data(class0 = 5000
, class1 = 5000 #count in class =1
,p1_0 = 0.2 # 1 - sp test 1
,p1_1 = 0.8 #se test 1
,p2_0 = 0.10 # 1 -sp test 2
,p2_1 = 0.8) # se test 2
res <- tvae_synthesize_binary(df, n_synth = 5000, p_class1 = 0.8, epochs = 100)
#head(res$synthetic_df)
#res$diagnostics
print(list(calc_se_sp_ci(df),calc_se_sp_ci(res$synthetic_df)))
#plot(res$training_loss$Epoch, res$training_loss$Loss, type="l", lwd=2)
#res$training_loss$loss
hui <- hui_walter_mle_se(table(df$test1,df$test2), table(res$synthetic_df$test1,res$synthetic_df$test2))
#se and sp estimates
#res$estimates   # MLEs on probability scale
#Check
list(hui$estimates, calc_se_sp_ci(df),calc_se_sp_ci(res$synthetic_df))
hui$se          # standard errors (Wald)
hui$ci          # Wald 95% CIs
hui$logLik
#all the necessary functions
source(here::here("hui_tvae_functions.R"))
df <- generate_real_data(class0 = 5000
, class1 = 5000 #count in class =1
,p1_0 = 0.2 # 1 - sp test 1
,p1_1 = 0.8 #se test 1
,p2_0 = 0.10 # 1 -sp test 2
,p2_1 = 0.8) # se test 2
synth.output <- tvae_synthesize_binary(df, n_synth = 5000, p_class1 = 0.8, epochs = 100)
#head(synth.output$synthetic_df)
#synth.output$diagnostics
#print(list(calc_se_sp_ci(df),calc_se_sp_ci(synth.output$synthetic_df)))
#####show the training curve
#plot(synth.output$training_loss$Epoch, synth.output$training_loss$Loss, type="l", lwd=2)
#synth.output$training_loss$loss
hui <- hui_walter_mle_se(
table(df$test1,df$test2)
, table(synth.output$synthetic_df$test1,synth.output$synthetic_df$test2))
#se and sp estimates
#res$estimates   # MLEs on probability scale
#Check
list(hui$estimates, calc_se_sp_ci(df),calc_se_sp_ci(synth.output$synthetic_df))
hui$se          # standard errors (Wald)
hui$ci          # Wald 95% CIs
hui$logLik
calc_se_sp(df)
hui$se          # standard errors (Wald)
hui$se          # standard errors (Wald)
names(hui$se)
names(calc_se_sp(df))
calc_se_sp(df)
names(hui$se)
as.vector(calc_se_sp(df))
calc_se_sp(df)
names(hui$se)
calc_se_sp(df)
as.vector(calc_se_sp(df))
calc_se_sp(df)
as.vector(calc_se_sp(df))
as.vector(t(calc_se_sp(df))
as.vector(t(calc_se_sp(df))
as.vector(t(calc_se_sp(df)))
calc_se_sp(df)
names(hui$se)
as.vector(t(calc_se_sp(df)))
calc_se_sp(df)
as.vector(t(calc_se_sp(df)))
as.vector((calc_se_sp(df))
as.vector((calc_se_sp(df))
as.vector(calc_se_sp(df))
calc_se_sp(df)
names(hui$se)
names(foo)<-c("Se1" ,"Sp1", "Se2" ,"Sp2")
foo<-as.vector(calc_se_sp(df))
names(foo)<-c("Se1" ,"Sp1", "Se2" ,"Sp2")
foo
names(foo)
names(hui$se)
names(foo)<-c("Se1" ,"Sp1", "Se2" ,"Sp2")
names(foo)
foo<-c(as.vector(calc_se_sp(df)),mean(df$class),mean(synth.output$synthetic_df$class))
names(hui$se)
foo<-c(as.vector(calc_se_sp(df)),mean(df$class),mean(synth.output$synthetic_df$class))
names(foo)<-c("Se1" ,"Sp1", "Se2" ,"Sp2"   ,  "Prev_pop1", "Prev_pop2")
names(foo)
foo
rbind(hui$se,foo)
cbind(hui$se,foo)
rbind(hui$se,foo)
hui.sim <- function() {
#####"real" dataset
df <- generate_real_data(class0 = 5000
, class1 = 5000 #count in class =1
,p1_0 = 0.2 # 1 - sp test 1
,p1_1 = 0.8 #se test 1
,p2_0 = 0.10 # 1 -sp test 2
,p2_1 = 0.8) # se test 2
######generate synthetic dataset
synth.output <- tvae_synthesize_binary(df, n_synth = 5000, p_class1 = 0.8, epochs = 100)
##### hui and walter
hui <- hui_walter_mle_se(
table(df$test1,df$test2)
, table(synth.output$synthetic_df$test1,synth.output$synthetic_df$test2))
#######make the output
foo<-c(as.vector(calc_se_sp(df)),mean(df$class),mean(synth.output$synthetic_df$class))
names(foo)<-c("Se1" ,"Sp1", "Se2" ,"Sp2"   ,  "Prev_pop1", "Prev_pop2")
return(rbind(hui$se,foo))
}
hui.sim()
plan(multisession, workers = 8)  # Use your available cores
library(furrr)
plan(multisession, workers = 8)  # Use your available cores
plan(multisession, workers = 8)  # Use your available cores
results <- future_map_dfr(1:5, ~ hui.sim())
results <- replicate(10,  hui.sim())
results
df <- generate_real_data(class0 = 5000
, class1 = 5000 #count in class =1
,p1_0 = 0.2 # 1 - sp test 1
,p1_1 = 0.8 #se test 1
,p2_0 = 0.10 # 1 -sp test 2
,p2_1 = 0.8) # se test 2
######generate synthetic dataset
synth.output <- tvae_synthesize_binary(df, n_synth = 5000, p_class1 = 0.8, epochs = 100)
##########display some checks and summaries-------------------------
#head(synth.output$synthetic_df)
#synth.output$diagnostics
#print(list(calc_se_sp_ci(df),calc_se_sp_ci(synth.output$synthetic_df)))
#####show the training curve---------------------------------
#plot(synth.output$training_loss$Epoch, synth.output$training_loss$Loss, type="l", lwd=2)
#synth.output$training_loss$loss
print(list(calc_se_sp_ci(df),calc_se_sp_ci(synth.output$synthetic_df)))
hui <- hui_walter_mle_se(
table(df$test1,df$test2)
, table(synth.output$synthetic_df$test1,synth.output$synthetic_df$test2))
#Check
list(hui$estimates, calc_se_sp_ci(df),calc_se_sp_ci(synth.output$synthetic_df))
hui$estimates
results <- replicate(3,  hui.sim())
results
rbind(hui$estimates,foo)
df <- generate_real_data(class0 = 5000
, class1 = 5000 #count in class =1
,p1_0 = 0.2 # 1 - sp test 1
,p1_1 = 0.8 #se test 1
,p2_0 = 0.10 # 1 -sp test 2
,p2_1 = 0.8) # se test 2
######generate synthetic dataset
synth.output <- tvae_synthesize_binary(df, n_synth = 5000, p_class1 = 0.8, epochs = 100)
##########display some checks and summaries-------------------------
#head(synth.output$synthetic_df)
#synth.output$diagnostics
print(list(calc_se_sp_ci(df),calc_se_sp_ci(synth.output$synthetic_df)))
#####show the training curve---------------------------------
#plot(synth.output$training_loss$Epoch, synth.output$training_loss$Loss, type="l", lwd=2)
#synth.output$training_loss$loss
print(list(calc_se_sp_ci(df),calc_se_sp_ci(synth.output$synthetic_df)))
#Check
list(hui$estimates, calc_se_sp_ci(df),calc_se_sp_ci(synth.output$synthetic_df))
rbind(hui$estimates,foo)
# --- Fix for joblib/loky resource_tracker warnings on restart ---
# These appear when reticulate's embedded Python shuts down and finds leftover semaphores or temp memmaps.
# This block sets up a stable temp dir, safe parallel backend, and silent teardown.
# Create a stable temp folder for joblib
dir.create("~/tmp/joblib", recursive = TRUE, showWarnings = FALSE)
Sys.setenv(JOBLIB_TEMP_FOLDER = "~/tmp/joblib")
# Optionally upgrade joblib/loky for better cleanup behavior
if (requireNamespace("reticulate", quietly = TRUE)) {
try(reticulate::py_install(
c("joblib>=1.4", "loky>=3.5"),
envname = "r-reticulate", pip = TRUE
))
}
# Define a Python-safe parallel example with clean exit
if (requireNamespace("reticulate", quietly = TRUE)) {
reticulate::py_run_string("
import os
os.makedirs(os.getenv('JOBLIB_TEMP_FOLDER', '/tmp'), exist_ok=True)
from joblib import Parallel, delayed, parallel_backend
def work(i):
# example workload
return i*i
# Use threading backend (no semaphores)
with parallel_backend('threading'):
OUT = Parallel(n_jobs=-1)(delayed(work)(i) for i in range(1000))
# Clean shutdown of workers
import multiprocessing as mp
for p in mp.active_children():
p.terminate()
")
out <- reticulate::py$OUT
print(str(out))
}
# Optional: silence resource_tracker warnings entirely (use sparingly)
Sys.setenv(PYTHONWARNINGS = "ignore:resource_tracker")
# Summary:
# - Prevents leaked semaphore warnings at R shutdown.
# - Keeps joblib temp files in one reusable folder.
# - Uses threads for safety (no process semaphores).
# - Safe to keep in .Rprofile or call before running reticulate simulations.
#all the necessary functions
source(here::here("hui_tvae_functions.R"))
hui.sim <- function() {
#####"real" dataset
df <- generate_real_data(class0 = 5000
, class1 = 5000 #count in class =1
,p1_0 = 0.2 # 1 - sp test 1
,p1_1 = 0.8 #se test 1
,p2_0 = 0.10 # 1 -sp test 2
,p2_1 = 0.8) # se test 2
######generate synthetic dataset
synth.output <- tvae_synthesize_binary(df, n_synth = 5000, p_class1 = 0.8, epochs = 100)
##### hui and walter
hui <- hui_walter_mle_se(
table(df$test1,df$test2)
, table(synth.output$synthetic_df$test1,synth.output$synthetic_df$test2))
#######make the output
foo<-c(as.vector(calc_se_sp(df)),mean(df$class),mean(synth.output$synthetic_df$class))
names(foo)<-c("Se1" ,"Sp1", "Se2" ,"Sp2"   ,  "Prev_pop1", "Prev_pop2")
return(rbind(hui$estimates,foo))
}
results <- replicate(3,  hui.sim())
results
hui.sim <- function() {
#####"real" dataset
df <- generate_real_data(class0 = 5000
, class1 = 5000 #count in class =1
,p1_0 = 0.2 # 1 - sp test 1
,p1_1 = 0.8 #se test 1
,p2_0 = 0.10 # 1 -sp test 2
,p2_1 = 0.8) # se test 2
######generate synthetic dataset
synth.output <- tvae_synthesize_binary(df, n_synth = 5000, p_class1 = 0.8, epochs = 100)
##### hui and walter
hui <- hui_walter_mle_se(
table(df$test1,df$test2)
, table(synth.output$synthetic_df$test1,synth.output$synthetic_df$test2))
#######make the output
real.data<-c(as.vector(calc_se_sp(df)),mean(df$class),mean(synth.output$synthetic_df$class))
names(real.data)<-c("Se1" ,"Sp1", "Se2" ,"Sp2"   ,  "Prev_pop1", "Prev_pop2")
hui.estimates <- hui$estimates
return(rbind(hui.estimates,real.data))
}
results <- replicate(3,  hui.sim())
results
as.data.frame(results)
unlist(results)
unlist(results)
is.list(results)
class(results)
melt(results)
library(reshape2)
melt(results)
as.data.frame.table(results)
slices <- array_branch(results, 3)   # list of matrices
flat <- do.call(rbind, slices)   # bind all slices vertically
flat
melt(results)
results_df <- melt(results) <- names(c("source", "stat","iteration","value"))
library(reshape2)
results_df <- melt(results) <- names(c("source", "stat","iteration","value"))
rehape2::results_df <- melt(results)
reshape2::results_df <- melt(results)
library(reshape2)
results_df <- melt(results)
setnames(results_df,c("source", "stat","iteration","value"))
names(results_df<-c("source", "stat","iteration","value")
library(reshape2)
library(reshape2)
results_df <- melt(results)
names(results_df)<-c("source", "stat","iteration","value")
results_df
results_df |> group_by(source,stat) |> summary(value)
results_df |> group_by(source,stat) |> summary()
results_df |> group_by(source,stat) |> summary(
mean = mean(.)
)
results_df |> group_by(source,stat) |> summary(
mean = mean(.)
)
results_df |> group_by(source,stat) |> summarize(
mean = mean(.)
)
results_df |> group_by(source,stat) |> summarize(
mean = mean(value)
)
results_df |> group_by(source,stat) |> summarize(
median = median(value)
, IQR = IQR(value)
)
results_df |> group_by(source,stat) %>%
summarise(
lower = quantile(value, 0.025),  # 2.5th percentile
upper = quantile(value, 0.975),  # 97.5th percentile
median_val = median(value),
.groups = "drop"
)
results_df |> group_by(source,stat) %>%
summarise(
lower = quantile(value, 0.025),  # 2.5th percentile
median_val = median(value),
upper = quantile(value, 0.975),  # 97.5th percentile
.groups = "drop"
)
results_df |> group_by(source,stat) %>%
summarise(
lower = quantile(value, 0.025),  # 2.5th percentile
median_val = median(value),
upper = quantile(value, 0.975),  # 97.5th percentile
.groups = "drop"
) |> arrange(stat)
results_df |> group_by(source,stat) %>%
summarise(
lower = quantile(value, 0.025),  # 2.5th percentile
median_val = median(value),
upper = quantile(value, 0.975),  # 97.5th percentile
.groups = "drop"
) |> arrange(stat)%>%
kbl() %>%
row_spec(which((1:nrow(df)) %% 4 %in% c(1, 2)), background = "#F2F2F2")
results_df |> group_by(source,stat) %>%
summarise(
lower = quantile(value, 0.025),  # 2.5th percentile
median_val = median(value),
upper = quantile(value, 0.975),  # 97.5th percentile
.groups = "drop"
) |> arrange(stat)%>%
kbl() %>%
row_spec(which((1:nrow(results_df)) %% 4 %in% c(1, 2)), background = "#F2F2F2")
results_summary%>%
kbl() %>%
row_spec(which((1:nrow(results_summary)) %% 4 %in% c(1, 2)), background = "#F2F2F2")
results_summary <- results_df |> group_by(source,stat) %>%
summarise(
lower = quantile(value, 0.025),  # 2.5th percentile
median_val = median(value),
upper = quantile(value, 0.975),  # 97.5th percentile
.groups = "drop"
) |> arrange(stat)
results_summary%>%
kbl() %>%
row_spec(which((1:nrow(results_summary)) %% 4 %in% c(1, 2)), background = "#F2F2F2")
results_summary%>%
kbl() %>%
row_spec(which((1:nrow(results_summary)) %% 4 %in% c(1, 2)), background = "#F2F2F2")
results_summary%>%
kbl() %>%
row_spec(which((1:nrow(df)) %% 4 %in% c(1, 2)), background = "#F2F2F2") %>%
kable_styling(full_width = FALSE, font_size = 12, bootstrap_options = c("striped"))
results_summarykbl() %>%
kable_paper(full_width = FALSE) %>%
pack_rows(index = rep(2, nrow(df) / 2), background = c("#F9F9F9", "#FFFFFF"))
results_summary|>kbl() %>%
kable_paper(full_width = FALSE) %>%
pack_rows(index = rep(2, nrow(df) / 2), background = c("#F9F9F9", "#FFFFFF"))
results_summary%>%
kbl() %>%
row_spec(which((1:nrow(df)) %% 4 %in% c(1, 2)), background = "#F2F2F2")
results_summary%>%
kbl() %>%
row_spec(which((1:nrow(results_summary)) %% 4 %in% c(1, 2)), background = "#F2F2F2")
results_summary%>%
%>%
results_summary%>%
# darker gray; you can go to "#BDBDBD" or even "#A6A6A6"
row_spec(pair_rows, background = "#C8C8C8", color = "black")
results_summary
n <- nrow(results_summary)
pair_rows <- which(gl(n, 2, labels = FALSE) %% 2 == 1)  # 1–2, 5–6, ...
kbl(results_summary) %>%
# darker gray; you can go to "#BDBDBD" or even "#A6A6A6"
row_spec(pair_rows, background = "#C8C8C8", color = "black")
n <- nrow(results_summary)
pair_rows <- which(gl(n, 2, labels = FALSE) %% 2 == 1)
kbl(results_summary) %>%
row_spec(pair_rows, background = "#A0A0A0", color = "black") %>%
kable_styling(full_width = FALSE)
kbl(df) %>%
# Shade odd-numbered pairs
row_spec(pair_odd, background = "#A0A0A0", color = "black") %>%
# Thick divider after each pair so blocks don’t visually run together
row_spec(last_in_pair, extra_css = "border-bottom: 3px solid #000;") %>%
kable_styling(full_width = FALSE)
df <- results_summary
n  <- nrow(df)
pair_odd      <- which(gl(n, 2, labels = FALSE) %% 2 == 1)  # rows 1–2, 5–6, ...
last_in_pair  <- seq(2, n, by = 2)                          # 2, 4, 6, ...
kbl(df) %>%
# Shade odd-numbered pairs
row_spec(pair_odd, background = "#A0A0A0", color = "black") %>%
# Thick divider after each pair so blocks don’t visually run together
row_spec(last_in_pair, extra_css = "border-bottom: 3px solid #000;") %>%
kable_styling(full_width = FALSE)
rm(df)
n  <- nrow(results_summary)
pair_odd      <- which(gl(n, 2, labels = FALSE) %% 2 == 1)  # rows 1–2, 5–6, ...
last_in_pair  <- seq(2, n, by = 2)                          # 2, 4, 6, ...
kbl(results_summary) %>%
# Shade odd-numbered pairs
row_spec(pair_odd, background = "#A0A0A0", color = "black") %>%
# Thick divider after each pair so blocks don’t visually run together
row_spec(last_in_pair, extra_css = "border-bottom: 3px solid #000;") %>%
kable_styling(full_width = FALSE)
results <- replicate(3,
hui.sim((
class0 = 5000
, class1 = 5000 #count in class =1
results <- replicate(3,
hui.sim(
class0 = 5000
, class1 = 5000 #count in class =1
,p1_0 = 0.2     # 1 - sp test 1
,p1_1 = 0.8     #se test 1
,p2_0 = 0.10    # 1 -sp test 2
,p2_1 = 0.8     # se test 2
,n_synth = 5000 # n for the tvae
, p_class1 = 0.8 # class proportion for the tvae
, epochs = 100  #number of training epochs
))
#all the necessary functions
source(here::here("hui_tvae_functions.R"))
results <- replicate(3,
hui.sim(
class0 = 5000
, class1 = 5000 #count in class =1
,p1_0 = 0.2     # 1 - sp test 1
,p1_1 = 0.8     #se test 1
,p2_0 = 0.10    # 1 -sp test 2
,p2_1 = 0.8     # se test 2
,n_synth = 5000 # n for the tvae
, p_class1 = 0.8 # class proportion for the tvae
, epochs = 100  #number of training epochs
))
library(reshape2)
results_df <- melt(results)
names(results_df)<-c("source", "stat","iteration","value")
#summarize the simulation
results_summary <- results_df |> group_by(source,stat) %>%
summarise(
lower = quantile(value, 0.025),  # 2.5th percentile
median_val = median(value),
upper = quantile(value, 0.975),  # 97.5th percentile
.groups = "drop"
) |> arrange(stat)
# print it nicely
n  <- nrow(results_summary)
pair_odd      <- which(gl(n, 2, labels = FALSE) %% 2 == 1)  # rows 1–2, 5–6, ...
last_in_pair  <- seq(2, n, by = 2)                          # 2, 4, 6, ...
kbl(results_summary) %>%
# Shade odd-numbered pairs
row_spec(pair_odd, background = "#A0A0A0", color = "black") %>%
# Thick divider after each pair so blocks don’t visually run together
row_spec(last_in_pair, extra_css = "border-bottom: 3px solid #000;") %>%
kable_styling(full_width = FALSE)
results <- replicate(100,
hui.sim(
class0 = 5000
, class1 = 5000 #count in class =1
,p1_0 = 0.2     # 1 - sp test 1
,p1_1 = 0.8     #se test 1
,p2_0 = 0.10    # 1 -sp test 2
,p2_1 = 0.8     # se test 2
,n_synth = 5000 # n for the tvae
, p_class1 = 0.8 # class proportion for the tvae
, epochs = 100  #number of training epochs
))
library(reshape2)
results_df <- melt(results)
names(results_df)<-c("source", "stat","iteration","value")
#summarize the simulation
results_summary <- results_df |> group_by(source,stat) %>%
summarise(
lower = quantile(value, 0.025),  # 2.5th percentile
median_val = median(value),
upper = quantile(value, 0.975),  # 97.5th percentile
.groups = "drop"
) |> arrange(stat)
# print it nicely
n  <- nrow(results_summary)
pair_odd      <- which(gl(n, 2, labels = FALSE) %% 2 == 1)  # rows 1–2, 5–6, ...
last_in_pair  <- seq(2, n, by = 2)                          # 2, 4, 6, ...
kbl(results_summary) %>%
# Shade odd-numbered pairs
row_spec(pair_odd, background = "#A0A0A0", color = "black") %>%
# Thick divider after each pair so blocks don’t visually run together
row_spec(last_in_pair, extra_css = "border-bottom: 3px solid #000;") %>%
kable_styling(full_width = FALSE)
