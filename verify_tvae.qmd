---
title: "Analysis"
date: "`r Sys.Date()`"
author: "Rich Evans, PhD, PSTAT"
format: pdf
number-sections: true
execute: 
  echo: true
output-file: "analysis_results"
reticulate:
  python: "/Users/richardevans/.virtualenvs/r-reticulate/bin/python"
---

This runs everything

What I do is look at the median for real.data and see if it falls within the hui confidence intervals. If they do, I call it "acceptable." The hui intervals are quite wide for n_real = 500.

small n_real take about 15 minutes. With n_real = 20,000 it takes 5.5 hours.


```{r}

#all the necessary functions
source(here::here("hui_tvae_functions2.R"))
```

RUN THIS TO REMOVE THE HUI PART AND JUST COMPARE "REAL" AND "SYNTHETIC" ESTIMATES
```{r}

#now the simulation function that returns a 3D array

hui.sim <- function(
  p_class1_real = 0.8,
  n_real = 500,
  p1_0 = 0.2, # 1 - sp test 1
  p1_1 = 0.8, #se test 1
  p2_0 = 0.10, # 1 -sp test 2
  p2_1 = 0.8, # se test 2
  n_synth = 5000, # n for the tvae
  p_class1 = 0.8, # class proportion for the tvae
  epochs = 100 #number of training epochs
) {
  #####"real" dataset
  df <- generate_real_data(
    p_class1_real = p_class1_real,
    n_real = n_real,
    p1_0 = p1_0, # 1 - sp test 1
    p1_1 = p1_1, #se test 1
    p2_0 = p2_0, # 1 -sp test 2
    p2_1 = p2_1
  ) # se test 2

  ######generate synthetic dataset
  synth.output <- tvae_synthesize_binary(
    df,
    n_synth = n_synth,
    p_class1 = p_class1,
    epochs = epochs
  )

  #suffle test 2 within class to destroy any dependence
synth_df_shuffled <- synth.output$synthetic_df  

# %>%
#   group_by(class) %>%
#   mutate(value = sample(test2)) %>%
#   ungroup()

  ##### hui and walter
 # hui <- hui_walter_mle_se(
 #   table(df$test1, df$test2),
 #   table(synth.output$synthetic_df$test1, synth.output$synthetic_df$test2)
 # )

  real.data <- c(as.vector(calc_se_sp(df)), mean(df$class), NA)
  names(real.data) <- c("Se1", "Sp1", "Se2", "Sp2", "Prev_pop1", "Prev_pop2")

  synthetic.data <- c(
    as.vector(calc_se_sp(synth_df_shuffled)),
    NA,
    mean(synth_df_shuffled$class)
  )
  names(synthetic.data) <- c(
    "Se1",
    "Sp1",
    "Se2",
    "Sp2",
    "Prev_pop1",
    "Prev_pop2"
  )

  hui.estimates <- c(NA,NA,NA)

  return(rbind(hui.estimates, real.data, synthetic.data))
}



```

this uses cond dep hui and walter

```{r}

library(tictoc)

tic("time_hui_sim")

results <- replicate(200,  
  hui.sim(
     p_class1_real = 0.8 # class proportion for the "real" training set
    ,p_class1 =      0.2 # class proportion for the synth
    ,n_real =        500 # n for the "real" training set
    ,n_synth =       500 # n for the tvae
    ,p1_0 =          0.2     # 1 - sp test 1
    ,p1_1 =          0.8     #se test 1
    ,p2_0 =          0.1    # 1 -sp test 2
    ,p2_1 =          0.8     # se test 2  
    , epochs =       600  #number of training epochs
  ))


#make the results into a nice table
#sim_summary_table(results)$table


sim_summary_table(results)$summary |> 
    filter(!source == "hui.estimates" & stat %in% c("Se2","Sp2","Se1","Sp1"))  %>%
  pivot_wider(
    id_cols = source,
    names_from = stat,
    values_from = median_val
  )


toc()
```




```{r}
# --- Fix for joblib/loky resource_tracker warnings on restart ---
# These appear when reticulate's embedded Python shuts down and finds leftover semaphores or temp memmaps.
# This block sets up a stable temp dir, safe parallel backend, and silent teardown.

# Create a stable temp folder for joblib
dir.create("~/tmp/joblib", recursive = TRUE, showWarnings = FALSE)
Sys.setenv(JOBLIB_TEMP_FOLDER = "~/tmp/joblib")

# Optionally upgrade joblib/loky for better cleanup behavior
if (requireNamespace("reticulate", quietly = TRUE)) {
  try(reticulate::py_install(
    c("joblib>=1.4", "loky>=3.5"),
    envname = "r-reticulate", pip = TRUE
  ))
}

# Define a Python-safe parallel example with clean exit
if (requireNamespace("reticulate", quietly = TRUE)) {
  reticulate::py_run_string("
import os
os.makedirs(os.getenv('JOBLIB_TEMP_FOLDER', '/tmp'), exist_ok=True)
from joblib import Parallel, delayed, parallel_backend

def work(i):
    # example workload
    return i*i

# Use threading backend (no semaphores)
with parallel_backend('threading'):
    OUT = Parallel(n_jobs=-1)(delayed(work)(i) for i in range(1000))

# Clean shutdown of workers
import multiprocessing as mp
for p in mp.active_children():
    p.terminate()
")
  out <- reticulate::py$OUT
  print(str(out))
}

# Optional: silence resource_tracker warnings entirely (use sparingly)
Sys.setenv(PYTHONWARNINGS = "ignore:resource_tracker")

# Summary:
# - Prevents leaked semaphore warnings at R shutdown.
# - Keeps joblib temp files in one reusable folder.
# - Uses threads for safety (no process semaphores).
# - Safe to keep in .Rprofile or call before running reticulate simulations.
```

